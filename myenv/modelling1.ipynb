{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/codespace/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path (update with actual file path)\n",
    "file_path = \"/workspaces/customer-sentiment-analysis/data/customer-review.csv\"\n",
    "\n",
    "# Read file, remove all quotes, and overwrite the file\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read().replace('\"', '')\n",
    "\n",
    "with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/customer-sentiment-analysis/myenv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Source</th>\n",
       "      <th>Date/Time</th>\n",
       "      <th>User ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Confidence Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this product!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>2023-06-15 09:23:14</td>\n",
       "      <td>@user123</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service was terrible.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Yelp Reviews</td>\n",
       "      <td>2023-06-15 11:45:32</td>\n",
       "      <td>user456</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This movie is amazing!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>IMDb</td>\n",
       "      <td>2023-06-15 14:10:22</td>\n",
       "      <td>moviefan789</td>\n",
       "      <td>London</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm so disappointed with their customer support.</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Online Forum</td>\n",
       "      <td>2023-06-15 17:35:11</td>\n",
       "      <td>forumuser1</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just had the best meal of my life!</td>\n",
       "      <td>Positive</td>\n",
       "      <td>TripAdvisor</td>\n",
       "      <td>2023-06-16 08:50:59</td>\n",
       "      <td>foodie22</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Text  Sentiment         Source  \\\n",
       "0                              I love this product!   Positive        Twitter   \n",
       "1                         The service was terrible.   Negative   Yelp Reviews   \n",
       "2                            This movie is amazing!   Positive           IMDb   \n",
       "3  I'm so disappointed with their customer support.   Negative   Online Forum   \n",
       "4                Just had the best meal of my life!   Positive    TripAdvisor   \n",
       "\n",
       "              Date/Time       User ID      Location   Confidence Score  \n",
       "0   2023-06-15 09:23:14      @user123      New York               0.85  \n",
       "1   2023-06-15 11:45:32       user456   Los Angeles               0.65  \n",
       "2   2023-06-15 14:10:22   moviefan789        London               0.92  \n",
       "3   2023-06-15 17:35:11    forumuser1       Toronto               0.78  \n",
       "4   2023-06-16 08:50:59      foodie22         Paris               0.88  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data \n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum() and word not in stopwords.words(\"english\")]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  I love this product!\n",
       "1                             The service was terrible.\n",
       "2                                This movie is amazing!\n",
       "3      I'm so disappointed with their customer support.\n",
       "4                    Just had the best meal of my life!\n",
       "                            ...                        \n",
       "91    Just had the most amazing vacation! I can't wa...\n",
       "92    The food at this restaurant was awful. Never g...\n",
       "93    I can't stop listening to this song. It's my n...\n",
       "94    Their website is so confusing and poorly desig...\n",
       "95    I had an incredible experience at the theme pa...\n",
       "Name: Text, Length: 96, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text'].apply(preprocess_text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df[' Sentiment'], test_size=0.2, random_state=42)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Positive', ' Negative', ' Negative', ' Positive'], dtype='<U9')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(\"/workspaces/customer-sentiment-analysis/model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
